{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coZgBzmGdANB"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c27chROCdk54",
        "outputId": "7e08abf5-5a07-4917-ccde-d675e668d95f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain_groq) (0.3.50)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.22.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.11.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.13.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (0.3.23)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.10.16)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (2.3.0)\n",
            "Downloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
            "Downloading groq-0.22.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain_groq\n",
            "Successfully installed groq-0.22.0 langchain_groq-0.3.2\n"
          ]
        }
      ],
      "source": [
        "pip install langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqdI2RUNe2Dn",
        "outputId": "acf37f28-4def-4ed2-e501-893d859ca951"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi==0.115.9 (from chromadb)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.23.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.1)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.16)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Collecting opentelemetry-util-http==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.0.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.31.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.23.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53800 sha256=79d672e58e327339061168d50da63debfb9122e506ee649bb66ef46650e4dddf\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, build, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.0 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.9 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.0 opentelemetry-exporter-otlp-proto-common-1.31.1 opentelemetry-exporter-otlp-proto-grpc-1.31.1 opentelemetry-instrumentation-0.52b1 opentelemetry-instrumentation-asgi-0.52b1 opentelemetry-instrumentation-fastapi-0.52b1 opentelemetry-proto-1.31.1 opentelemetry-util-http-0.52b1 overrides-7.7.0 posthog-3.23.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 starlette-0.45.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        }
      ],
      "source": [
        "pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Kr2jnpMd49P",
        "outputId": "26056c65-d9d0-491a-d8f0-aa200a509e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.5-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting cmudict (from textstat)\n",
            "  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (8.6.1)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\n",
            "Downloading textstat-0.7.5-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, cmudict, textstat\n",
            "Successfully installed cmudict-1.0.32 pyphen-0.17.2 textstat-0.7.5\n"
          ]
        }
      ],
      "source": [
        "pip install textstat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9NM30-ldxYo",
        "outputId": "76162e88-d72d-485b-b40a-efad2d137098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting summa\n",
            "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.11/dist-packages (from summa) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy>=0.19->summa) (2.0.2)\n",
            "Building wheels for collected packages: summa\n",
            "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54387 sha256=7765ae70d69d23ec7edb628daa5a30d5208add69c272f2a0ecd46b8b2c2a927d\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/2d/7a/abce87c4ea233f8dcca0d99b740ac0257eced1f99a124a0e1f\n",
            "Successfully built summa\n",
            "Installing collected packages: summa\n",
            "Successfully installed summa-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install summa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBWnMgzHc-10"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "import uuid\n",
        "import chromadb\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from summa import keywords\n",
        "import textstat\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6KhR-E0duUW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Load the dataset\n",
        "df = pd.read_excel(\"/content/Online_Retail_email.xlsx\")\n",
        "\n",
        "# Drop rows where 'Description' is missing\n",
        "df = df.dropna(subset=[\"Description\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ryJI7UzveeWf",
        "outputId": "53cf2fc1-89b1-4ff7-8c0b-aeeae2e43c39"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3e32b0a8-99aa-44f1-9e1a-712ddfbfe84c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "      <th>Email</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>536365</td>\n",
              "      <td>85123A</td>\n",
              "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "      <td>2.55</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Ebony39@gmail.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>536365</td>\n",
              "      <td>71053</td>\n",
              "      <td>WHITE METAL LANTERN</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "      <td>3.39</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Mark36@gmail.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>536365</td>\n",
              "      <td>84406B</td>\n",
              "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
              "      <td>8</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "      <td>2.75</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Shane85@gmail.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>536365</td>\n",
              "      <td>84029G</td>\n",
              "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "      <td>3.39</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Mary34@gmail.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>536365</td>\n",
              "      <td>84029E</td>\n",
              "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "      <td>3.39</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Charles30@gmail.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e32b0a8-99aa-44f1-9e1a-712ddfbfe84c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e32b0a8-99aa-44f1-9e1a-712ddfbfe84c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e32b0a8-99aa-44f1-9e1a-712ddfbfe84c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df3feebb-321d-4c3f-b58e-30c7d53a3e38\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df3feebb-321d-4c3f-b58e-30c7d53a3e38')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df3feebb-321d-4c3f-b58e-30c7d53a3e38 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  InvoiceNo StockCode                          Description  Quantity  \\\n",
              "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
              "1    536365     71053                  WHITE METAL LANTERN         6   \n",
              "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
              "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
              "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
              "\n",
              "          InvoiceDate  UnitPrice  CustomerID         Country  \\\n",
              "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom   \n",
              "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom   \n",
              "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom   \n",
              "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom   \n",
              "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom   \n",
              "\n",
              "                 Email  \n",
              "0    Ebony39@gmail.com  \n",
              "1     Mark36@gmail.com  \n",
              "2    Shane85@gmail.com  \n",
              "3     Mary34@gmail.com  \n",
              "4  Charles30@gmail.com  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4ktxMsPeB4X"
      },
      "source": [
        "# **Recommender Email Automation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocSmFX2jeIWe"
      },
      "outputs": [],
      "source": [
        "# Initialize vector store\n",
        "client = chromadb.PersistentClient('vectorstore')\n",
        "collection = client.get_or_create_collection(name=\"products\")\n",
        "\n",
        "# Populate the vector store with product descriptions (if not already populated)\n",
        "if not collection.count():\n",
        "    for _, row in df.iterrows():\n",
        "        collection.add(documents=row[\"Description\"],\n",
        "                       metadatas={\"StockCode\": row[\"StockCode\"], \"Description\": row[\"Description\"]},\n",
        "                       ids=[str(uuid.uuid4())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERCXl_8reyr1"
      },
      "outputs": [],
      "source": [
        "# Extract customer purchases\n",
        "def get_customer_purchases(customer_id):\n",
        "    purchases = df[df[\"CustomerID\"] == customer_id]\n",
        "    products_bought = purchases[\"Description\"].tolist()\n",
        "    return products_bought\n",
        "\n",
        "# Get relevant product recommendations\n",
        "def get_product_recommendation(products_bought, n_results=3):\n",
        "    query_result = collection.query(query_texts=products_bought, n_results=n_results)\n",
        "    recommended_products = query_result.get('metadatas', [[]])\n",
        "    return recommended_products[0] if recommended_products else []\n",
        "\n",
        "# Extract SEO Long-Tail Keywords using TextRank and N-Grams\n",
        "def extract_long_tail_keywords(text, n=2):\n",
        "    vectorizer = CountVectorizer(ngram_range=(1, n), stop_words='english')\n",
        "    ngrams = vectorizer.fit_transform([text])\n",
        "    vocab = vectorizer.get_feature_names_out()\n",
        "    return keywords.keywords(' '.join(vocab)).split('\\n')[:5]  # Get top 5 long-tail phrases\n",
        "\n",
        "# Get Readability Score\n",
        "def get_readability_score(text):\n",
        "    return textstat.flesch_reading_ease(text)\n",
        "\n",
        "# Improve Readability\n",
        "def improve_readability(text):\n",
        "    score = get_readability_score(text)\n",
        "    if score < 50:  # Low readability\n",
        "        prompt_fix = PromptTemplate.from_template(\"Rewrite this for better readability:\\n{text}\")\n",
        "        return (prompt_fix | llm).invoke({\"text\": text}).content\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3YyH_GbfR0V"
      },
      "outputs": [],
      "source": [
        "# LLM Configuration\n",
        "llm = ChatGroq(\n",
        "    temperature=0.7,\n",
        "    groq_api_key='',\n",
        "    model_name=\"llama-3.3-70b-versatile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxPwVeabfWVV"
      },
      "outputs": [],
      "source": [
        "# Email Prompt Template\n",
        "prompt_email = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    ### CUSTOMER PURCHASE DATA:\n",
        "    Customer ID: {customer_id}\n",
        "    Products Bought: {products_bought}\n",
        "    Suggested Product: {suggested_product} ({suggested_product_desc})\n",
        "\n",
        "    ### INSTRUCTION:\n",
        "    Write a personalized and professional email to a customer who recently bought the listed products.\n",
        "    - Start with a warm greeting and thank them for their purchase.\n",
        "    - Mention the specific products they bought.\n",
        "    - Suggest a related product based on their purchase.\n",
        "    - End with an invitation to shop again.\n",
        "    - Keep the email friendly, conversational, and professional.\n",
        "    - Do NOT include any marketing jargon, budget details, or irrelevant content.\n",
        "    - DO NOT provide a preamble, only return the email content.\n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxS_4ByCfYPU"
      },
      "outputs": [],
      "source": [
        "# Generate email with multiple product recommendations\n",
        "\n",
        "def generate_email(customer_id):\n",
        "    products_bought = get_customer_purchases(customer_id)\n",
        "    suggested_products_data = get_product_recommendation(products_bought)\n",
        "\n",
        "    suggested_products = []\n",
        "    for product_data in suggested_products_data:\n",
        "        suggested_product = product_data.get('StockCode', 'a special recommendation')\n",
        "        suggested_product_desc = product_data.get('Description', 'a product we think you\\'ll love!')\n",
        "        suggested_products.append(f\"{suggested_product} ({suggested_product_desc})\")\n",
        "\n",
        "    # If no recommendations found, suggest a special product\n",
        "    if not suggested_products:\n",
        "        suggested_products.append(\"a special recommendation (a product we think you'll love!)\")\n",
        "\n",
        "    # Join all the recommended products into a list format\n",
        "    suggested_products_str = '\\n- '.join(suggested_products)\n",
        "\n",
        "    chain_email = prompt_email | llm\n",
        "    response = chain_email.invoke({\n",
        "        \"customer_id\": customer_id,\n",
        "        \"products_bought\": products_bought,\n",
        "        \"suggested_product\": suggested_products_str,\n",
        "        \"suggested_product_desc\": \", \".join([product_data.get('Description', 'a product we think you\\'ll love!') for product_data in suggested_products_data])  # Corrected this part\n",
        "    })\n",
        "    return response.content\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A8AoT4ffZ21"
      },
      "outputs": [],
      "source": [
        "# Send email function\n",
        "def send_email(to, subject, body, sender_email, sender_password):\n",
        "    msg = MIMEText(body, 'plain')\n",
        "    msg['Subject'] = subject\n",
        "    msg['From'] = sender_email\n",
        "    msg['To'] = to\n",
        "    print(to)\n",
        "    print(subject)\n",
        "    print(body)\n",
        "\n",
        "    try:\n",
        "        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:\n",
        "            server.login(sender_email, sender_password)\n",
        "            server.send_message(msg)\n",
        "        print(f\"Email sent successfully to {to}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error sending email to {to}: {e}\")\n",
        "\n",
        "# Separate Section for Social Media Post, Readability Score, and Meta Tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwctFasegmGt",
        "outputId": "dd8e41e1-f107-49ce-8e1d-ef3a633c2699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kenneth42@gmail.com\n",
            "Personalized Product Recommendation\n",
            "Dear valued customer,\n",
            "\n",
            "A warm welcome and thank you for your recent purchase with us. We're thrilled that you've chosen to take home some of our unique items, including the 'SET 3 PAPER VINTAGE CHICK PAPER EGG', 'ANTIQUE SILVER TEA GLASS ENGRAVED', 'GLASS CHALICE GREEN LARGE', 'ANTIQUE TALL SWIRLGLASS TRINKET POT', 'TWO DOOR CURIO CABINET', 'SMALL GLASS SUNDAE DISH CLEAR', 'LARGE HANGING IVORY & RED WOOD BIRD', 'ROCKING HORSE RED CHRISTMAS', 'RED ROCKING HORSE HAND PAINTED', 'STAR WREATH DECORATION WITH BELL', and 'HEART WREATH DECORATION WITH BELL'. We hope you're enjoying these beautiful pieces and that they're bringing a touch of elegance to your home.\n",
            "\n",
            "We've noticed that you have a keen eye for vintage and unique items, and we think you might love our 'BOX OF VINTAGE ALPHABET BLOCKS' or 'BOX OF VINTAGE JIGSAW BLOCKS'. These classic blocks are not only a delightful decorative addition but also a thoughtful way to share a piece of nostalgia with loved ones. Alternatively, if you're looking for something a bit more whimsical, our 'PANDA AND BUNNIES STICKER SHEET' could be just the thing to add a playful touch to your space.\n",
            "\n",
            "We invite you to visit us again and explore our collection. We're always adding new and exciting items, and we're confident you'll find something that catches your eye. Thank you once more for your business, and we look forward to serving you again in the future.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Email sent successfully to Kenneth42@gmail.com\n"
          ]
        }
      ],
      "source": [
        "# Example Usage: Sending email to a specific customer\n",
        "customer_id = 17856  # Example customer ID\n",
        "email_content = generate_email(customer_id)\n",
        "\n",
        "sender_email = \"mrunaldgund04@gmail.com\"  # Replace with your email\n",
        "sender_password = \"buvs vwzc waug wwvv\"  # Replace with your password\n",
        "\n",
        "# Get the customer's email address\n",
        "customer_email = df[df['CustomerID'] == customer_id]['Email'].iloc[0]\n",
        "\n",
        "# Send the email\n",
        "subject = \"Personalized Product Recommendation\"\n",
        "send_email(customer_email, subject, email_content, sender_email, sender_password)\n",
        "\n",
        "# Separate cell for Social Media Post and Meta Tags\n",
        "product_name = \"WHITE HANGING HEART T-LIGHT HOLDER\"\n",
        "product_description = \"A charming white heart-shaped tea light holder that adds warmth to any space.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LKRtJOGf2Y8"
      },
      "source": [
        "# **Calendar JSON**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTUs_xixfbv0",
        "outputId": "2992a308-121a-4cf6-fbc7-69135acd1f87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved event_calendar.json successfully.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "prompt = PromptTemplate.from_template(\"\"\"\n",
        "You are an assistant that helps marketers.\n",
        "\n",
        "Generate a valid JSON list of globally recognized upcoming events in 2025 (including holidays and UN international days). For each event, include:\n",
        "- \"name\": Name of the event\n",
        "- \"date\": Date in YYYY-MM-DD format\n",
        "- \"categories\": List of marketing categories (e.g., gifts, eco-friendly, electronics, food)\n",
        "\n",
        "Only output a valid JSON array. No explanation.\n",
        "\"\"\")\n",
        "\n",
        "# Chain using latest LangChain style\n",
        "chain = prompt | llm\n",
        "\n",
        "# Run the chain\n",
        "response = chain.invoke({})\n",
        "\n",
        "# Extract content\n",
        "raw_output = response.content if hasattr(response, \"content\") else str(response)\n",
        "\n",
        "# Save as JSON\n",
        "try:\n",
        "    events = json.loads(raw_output)\n",
        "    with open(\"event_calendar.json\", \"w\") as f:\n",
        "        json.dump(events, f, indent=4)\n",
        "    print(\"✅ Saved event_calendar.json successfully.\")\n",
        "except json.JSONDecodeError as e:\n",
        "    print(\"❌ Invalid JSON:\", e)\n",
        "    print(\"Raw response:\\n\", raw_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIIvWT74gAFT",
        "outputId": "6b26b701-c19f-4d7c-d9a3-683e80d8de85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inferred location for 'New Year's Day': Times Square\n",
            "Inferred location for 'International Women's Day': Global\n",
            "Inferred location for 'Earth Day': United States\n",
            "Inferred location for 'Easter Sunday': Vatican City\n",
            "Inferred location for 'World Health Day': Geneva\n",
            "Inferred location for 'Mother's Day': United States\n",
            "Inferred location for 'World Environment Day': India\n",
            "Inferred location for 'Father's Day': United States\n",
            "Inferred location for 'International Day of Friendship': Brazil\n",
            "Inferred location for 'Back to School': United States\n",
            "Inferred location for 'World Literacy Day': India\n",
            "Inferred location for 'Halloween': United States\n",
            "Inferred location for 'World Food Day': Rome\n",
            "Inferred location for 'Black Friday': United States\n",
            "Inferred location for 'Cyber Monday': United States\n",
            "Inferred location for 'Christmas Day': Vatican City\n",
            "Inferred location for 'New Year's Eve': Times Square\n",
            "✅ Updated JSON saved to updated_event_calendar.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize the LLM\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key='',\n",
        "    model_name=\"llama3-70b-8192\"\n",
        ")\n",
        "\n",
        "# Define the prompt template for querying the location\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a knowledgeable assistant.\n",
        "\n",
        "For the given event name, infer the most likely location where this event is widely celebrated. Respond with just the location name.\n",
        "\n",
        "Event: {event_name}\n",
        "\"\"\")\n",
        "\n",
        "# Define the chain\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# Function to update the JSON file with locations\n",
        "def add_locations_to_json(input_file, output_file):\n",
        "    \"\"\"\n",
        "    Load a JSON file, use LLM to infer locations for events, and save the updated file.\n",
        "\n",
        "    Parameters:\n",
        "    - input_file: Path to the input JSON file containing events.\n",
        "    - output_file: Path to save the updated JSON file with locations.\n",
        "    \"\"\"\n",
        "    # Load the events JSON\n",
        "    with open(input_file, \"r\") as f:\n",
        "        events_data = json.load(f)\n",
        "\n",
        "    # Iterate through events and add locations\n",
        "    for event in events_data:\n",
        "        if \"location\" not in event or not event[\"location\"]:  # If location is missing\n",
        "            event_name = event.get(\"name\", \"Unknown Event\")\n",
        "            try:\n",
        "                # Use the LLM to infer the location\n",
        "                location = chain.invoke({\"event_name\": event_name}).strip()\n",
        "                event[\"location\"] = location  # Update the event with the inferred location\n",
        "                print(f\"Inferred location for '{event_name}': {location}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error inferring location for '{event_name}': {e}\")\n",
        "                event[\"location\"] = \"Unknown\"  # Set default location in case of failure\n",
        "\n",
        "    # Save the updated JSON\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(events_data, f, indent=4)\n",
        "\n",
        "    print(f\"✅ Updated JSON saved to {output_file}\")\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = \"event_calendar.json\"  # Input JSON file path\n",
        "    output_file = \"updated_event_calendar.json\"  # Output JSON file path with locations\n",
        "    add_locations_to_json(input_file, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGeB6voAhJ_B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqWzkoytP_zW"
      },
      "source": [
        "# **Product Category JSON**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_CGckDKQEGc",
        "outputId": "c55d12d1-7fc5-480f-8763-47bb07ca3c35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📦 Starting keyword-based categorization...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Categorizing products: 100%|██████████| 4223/4223 [00:00<00:00, 83956.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Categorization complete! Saved to 'product_categories_keywords.json'.\n",
            "⏱️ Execution Time: 0.07 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "# Load the product list from the dataset\n",
        "\n",
        "product_list = df['Description'].dropna().unique().tolist()\n",
        "\n",
        "# Define categories and associated keywords\n",
        "category_keywords = {\n",
        "    \"Home Decor\": [\"cushion\", \"vase\", \"frame\", \"mirror\", \"wall\", \"canvas\", \"plaque\", \"clock\", \"table\", \"chair\", \"basket\", \"lantern\"],\n",
        "    \"Kitchenware\": [\"mug\", \"plate\", \"bowl\", \"cup\", \"spoon\", \"fork\", \"knife\", \"dish\", \"teapot\", \"coaster\", \"napkin\", \"jug\", \"pan\", \"cutlery\", \"glass\"],\n",
        "    \"Toys\": [\"toy\", \"puzzle\", \"game\", \"play\", \"yo-yo\", \"doll\", \"train\", \"car\", \"kite\", \"ball\", \"jump rope\", \"puppet\"],\n",
        "    \"Stationery\": [\"pen\", \"pencil\", \"notebook\", \"ruler\", \"sharpener\", \"eraser\", \"diary\", \"journal\", \"sticky notes\", \"highlighter\", \"binder\", \"folder\",\"book\",\"education\"],\n",
        "    \"Lighting\": [\"lamp\", \"lantern\", \"light\", \"candle\", \"bulb\", \"chandelier\", \"shade\", \"sconce\"],\n",
        "    \"Gifts\": [\"gift\", \"set\", \"pack\", \"present\", \"hamper\", \"wrap\", \"box\", \"tag\", \"surprise\"],\n",
        "    \"Accessories\": [\"scarf\", \"bag\", \"wallet\", \"belt\", \"hat\", \"cap\", \"gloves\", \"umbrella\", \"keyring\", \"mirror\", \"watch\"],\n",
        "    \"Electronics\": [\"usb\", \"charger\", \"speaker\", \"headphones\", \"battery\", \"cable\", \"adapter\"],\n",
        "    \"Holiday-themed\": [\"christmas\", \"easter\", \"valentine\", \"halloween\", \"holiday\", \"xmas\", \"tree\", \"bauble\", \"stocking\", \"santa\", \"reindeer\"],\n",
        "    \"Miscellaneous\": []  # fallback\n",
        "}\n",
        "\n",
        "# Function to categorize using keywords\n",
        "def categorize_by_keywords(description):\n",
        "    desc = str(description).lower()\n",
        "\n",
        "    if desc.isdigit():  # Optional: Skip pure-number descriptions\n",
        "        return \"Miscellaneous\"\n",
        "\n",
        "    for category, keywords in category_keywords.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in desc:\n",
        "                return category\n",
        "    return \"Miscellaneous\"\n",
        "\n",
        "# Function to run categorization with tqdm\n",
        "def categorize_products_keyword_based(product_list):\n",
        "    results = defaultdict(list)\n",
        "    for product in tqdm(product_list, desc=\"Categorizing products\"):\n",
        "        category = categorize_by_keywords(product)\n",
        "        results[category].append(product)\n",
        "    return results\n",
        "\n",
        "# Run the categorization\n",
        "print(\"📦 Starting keyword-based categorization...\")\n",
        "start_time = time.time()\n",
        "categorized_results = categorize_products_keyword_based(product_list)\n",
        "\n",
        "# Save results to a JSON file\n",
        "with open(\"product_categories_keywords.json\", \"w\") as f:\n",
        "    json.dump(categorized_results, f, indent=4)\n",
        "\n",
        "print(f\"✅ Categorization complete! Saved to 'product_categories_keywords.json'.\")\n",
        "print(f\"⏱️ Execution Time: {time.time() - start_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ncCHVsXQ47m"
      },
      "source": [
        "# **Event_to_Product_Mapping JSON**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eG_RhM3RAML",
        "outputId": "7aa71b09-8309-4594-931e-baa2bd91114e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mapping saved to event_to_product_mapping.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# Load your product categories\n",
        "product_categories = [\n",
        "    \"Lighting\", \"Home Decor\", \"Kitchenware\", \"Miscellaneous\", \"Gifts\",\n",
        "    \"Toys\", \"Holiday-themed\", \"Accessories\", \"Stationery\", \"Electronics\"\n",
        "]\n",
        "\n",
        "# Initialize LangChain Groq LLM\n",
        "llm = ChatGroq(\n",
        "    temperature=0.7,\n",
        "    groq_api_key='',\n",
        "    model_name=\"llama-3.3-70b-versatile\"\n",
        ")\n",
        "\n",
        "# Define the prompt template for mapping\n",
        "mapping_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Given the following list of general product categories:\n",
        "    {product_categories}\n",
        "\n",
        "    And the following categories from an event in an event calendar:\n",
        "    {event_categories}\n",
        "\n",
        "    Map each event category to the most relevant general product category.\n",
        "    Return the mapping as a *valid JSON object* where keys are the event categories\n",
        "    and values are the corresponding general product categories.\n",
        "    If an event category doesn't clearly fit into any of the general\n",
        "    product categories, use \"Miscellaneous\" as the mapping.\n",
        "\n",
        "    **Return ONLY the JSON object. Ensure there are no leading/trailing characters\n",
        "    outside of the JSON structure.**\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "def load_event_calendar(event_calendar_file):\n",
        "    \"\"\"Loads the event calendar JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(event_calendar_file, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Event calendar file not found at {event_calendar_file}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Could not decode JSON from {event_calendar_file}\")\n",
        "        return None\n",
        "\n",
        "def map_event_categories_with_llm(event_categories, product_categories, llm):\n",
        "    \"\"\"Uses LLM to map event categories to general product categories.\"\"\"\n",
        "    chain = mapping_prompt | llm.with_config(run_name=\"event_category_mapping\")\n",
        "    response = chain.invoke({\n",
        "        \"product_categories\": \", \".join(product_categories),\n",
        "        \"event_categories\": \", \".join(event_categories)\n",
        "    })\n",
        "    raw_response = response.content.strip()  # Remove leading/trailing whitespace\n",
        "\n",
        "    # Try to find the start and end of the JSON object\n",
        "    start_index = raw_response.find('{')\n",
        "    end_index = raw_response.rfind('}')\n",
        "\n",
        "    if start_index != -1 and end_index != -1 and start_index < end_index:\n",
        "        json_string = raw_response[start_index:end_index + 1]\n",
        "        try:\n",
        "            return json.loads(json_string)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error: Could not decode cleaned LLM response to JSON: {e}\")\n",
        "            print(f\"Cleaned LLM Response: {json_string}\")\n",
        "            print(f\"Raw LLM Response: {raw_response}\")\n",
        "            return {}\n",
        "    else:\n",
        "        print(f\"Error: Could not find valid JSON boundaries in LLM response.\")\n",
        "        print(f\"Raw LLM Response: {raw_response}\")\n",
        "        return {}\n",
        "\n",
        "def process_event_calendar_and_map(event_calendar_file, product_categories):\n",
        "    \"\"\"\n",
        "    Loads the event calendar, extracts categories for each event, and maps\n",
        "    them to the provided product categories using an LLM.\n",
        "    \"\"\"\n",
        "    event_calendar_data = load_event_calendar(event_calendar_file)\n",
        "    if not event_calendar_data:\n",
        "        return None\n",
        "\n",
        "    event_to_product_mapping = {}\n",
        "    for event in event_calendar_data:\n",
        "        event_name = event.get('name')\n",
        "        event_categories = event.get('categories', [])\n",
        "\n",
        "        if event_name and event_categories:\n",
        "            mapping_result = map_event_categories_with_llm(event_categories, product_categories, llm)\n",
        "            event_to_product_mapping[event_name] = mapping_result\n",
        "        elif event_name:\n",
        "            event_to_product_mapping[event_name] = {}\n",
        "\n",
        "    return event_to_product_mapping\n",
        "\n",
        "# Example Usage:\n",
        "event_calendar_file = \"updated_event_calendar.json\"\n",
        "output_file = \"event_to_product_mapping.json\"\n",
        "\n",
        "# Process the event calendar and get the mappings\n",
        "event_to_product_mapping = process_event_calendar_and_map(event_calendar_file, product_categories)\n",
        "\n",
        "if event_to_product_mapping:\n",
        "    # Save the mapping to a JSON file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(event_to_product_mapping, f, indent=4)\n",
        "    print(f\"Mapping saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W7KntZkiDoq"
      },
      "source": [
        "# **Social media post**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2stUTS6yiHFJ",
        "outputId": "73aa1f22-4fe8-4269-d96e-4615448e1f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting instagrapi\n",
            "  Downloading instagrapi-2.1.3.tar.gz (102 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/102.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests<3.0,>=2.25.1 in /usr/local/lib/python3.11/dist-packages (from instagrapi) (2.32.3)\n",
            "Requirement already satisfied: PySocks==1.7.1 in /usr/local/lib/python3.11/dist-packages (from instagrapi) (1.7.1)\n",
            "Collecting pydantic==2.10.1 (from instagrapi)\n",
            "  Downloading pydantic-2.10.1-py3-none-any.whl.metadata (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.7/169.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex==3.21.0 (from instagrapi)\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.10.1->instagrapi) (0.7.0)\n",
            "Collecting pydantic-core==2.27.1 (from pydantic==2.10.1->instagrapi)\n",
            "  Downloading pydantic_core-2.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.10.1->instagrapi) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.25.1->instagrapi) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.25.1->instagrapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.25.1->instagrapi) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.25.1->instagrapi) (2025.1.31)\n",
            "Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.1-py3-none-any.whl (455 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.3/455.3 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: instagrapi\n",
            "  Building wheel for instagrapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for instagrapi: filename=instagrapi-2.1.3-py3-none-any.whl size=116362 sha256=f2f1930cbe0f067e54c0c7f354dc2f056e2003d000d09bf553681ffb6c560d20\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/c0/63/7ad4ef727751385676d1987f63b99b76c56adbbd043c17aa59\n",
            "Successfully built instagrapi\n",
            "Installing collected packages: pydantic-core, pycryptodomex, pydantic, instagrapi\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.1\n",
            "    Uninstalling pydantic_core-2.33.1:\n",
            "      Successfully uninstalled pydantic_core-2.33.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.2\n",
            "    Uninstalling pydantic-2.11.2:\n",
            "      Successfully uninstalled pydantic-2.11.2\n",
            "Successfully installed instagrapi-2.1.3 pycryptodomex-3.21.0 pydantic-2.10.1 pydantic-core-2.27.1\n"
          ]
        }
      ],
      "source": [
        "pip install instagrapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmPPWCcWiJDQ"
      },
      "outputs": [],
      "source": [
        "from instagrapi import Client\n",
        "\n",
        "def post_to_instagram(username, password, post_text, image_path=None):\n",
        "    \"\"\"\n",
        "    Posts content to Instagram.\n",
        "\n",
        "    Args:\n",
        "        username: Instagram username.\n",
        "        password: Instagram password.\n",
        "        post_text: The text content of the post.\n",
        "        image_path: Optional path to an image file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cl = Client()\n",
        "        cl.login(username, password)\n",
        "\n",
        "        if image_path:\n",
        "            cl.photo_upload(\n",
        "                path=image_path,\n",
        "                caption=post_text\n",
        "            )\n",
        "            print(\"Successfully posted image to Instagram\")\n",
        "        else:\n",
        "            # Instagram doesn't support text-only posts in the same way as other platforms\n",
        "            # You could consider creating a simple image with the text\n",
        "            print(\"Text-only posts are not directly supported. Consider using an image.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error posting to Instagram: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiVh4sHjiTcP"
      },
      "outputs": [],
      "source": [
        "# Separate Section for Social Media Post, Readability Score, and Meta Tags\n",
        "\n",
        "def generate_social_media_post_and_meta_tags(product_name, product_description):\n",
        "    # Generate Social Media Post and Readability Score\n",
        "    keywords_list = extract_long_tail_keywords(product_description)\n",
        "    readability_score = get_readability_score(product_description)\n",
        "    improved_description = improve_readability(product_description)\n",
        "\n",
        "    prompt_social = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        ### PRODUCT DETAILS:\n",
        "        Product Name: {product_name}\n",
        "        Description: {product_description}\n",
        "        Keywords: {keywords}\n",
        "\n",
        "        ### INSTRUCTION:\n",
        "        Write an engaging social media post for this product.\n",
        "        - Highlight its unique features.\n",
        "        - Use the provided keywords naturally.\n",
        "        - Include a strong call-to-action.\n",
        "        - Keep it short, compelling, and brand-friendly.\n",
        "        -Don't give caption like chatgpt humanize it and don't add before and after of the cpation\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chain_social = prompt_social | llm\n",
        "    social_post_response = chain_social.invoke({\n",
        "        \"product_name\": product_name,\n",
        "        \"product_description\": improved_description,\n",
        "        \"keywords\": ', '.join(keywords_list)\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "    # Generate Meta Tags\n",
        "    def generate_meta_tags(product_name, product_description):\n",
        "        meta_title = f\"{product_name} | Best Deals & Features\"\n",
        "        meta_description = f\"{product_description[:150]}...\"  # Trimmed for length\n",
        "        meta_keywords = ', '.join(keywords_list)\n",
        "        return {\n",
        "            \"title\": meta_title,\n",
        "            \"description\": meta_description,\n",
        "            \"keywords\": meta_keywords\n",
        "        }\n",
        "\n",
        "    meta_tags = generate_meta_tags(product_name, product_description)\n",
        "\n",
        "    return {\n",
        "        \"post_text\": social_post_response.content,\n",
        "        \"readability_score\": readability_score,\n",
        "        \"meta_tags\": meta_tags\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8GHBVlTiZmq",
        "outputId": "da201b27-6bac-44ee-de8d-be03570e3238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Image saved successfully at: /content/output.png\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import io\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Replace with your actual API key\n",
        "HF_API_KEY = \"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\"\n",
        "API_URL = \"https://api-inference.huggingface.co/models/ZB-Tech/Text-to-Image\"\n",
        "headers = {\"Authorization\": f\"Bearer {HF_API_KEY}\"}\n",
        "\n",
        "def query(payload):\n",
        "    response = requests.post(API_URL, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"Error:\", response.status_code, response.text)\n",
        "        return None\n",
        "    return response.content\n",
        "\n",
        "# Querying image\n",
        "image_bytes = query({\n",
        "    \"inputs\": \"WHITE HANGING HEART T-LIGHT HOLDER\",\n",
        "})\n",
        "\n",
        "# Processing and saving image\n",
        "if image_bytes:\n",
        "    try:\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "        image.show()\n",
        "\n",
        "        # Save with full path\n",
        "        save_path = os.path.join(os.getcwd(), \"output.png\")\n",
        "        image.save(save_path)\n",
        "        print(f\"✅ Image saved successfully at: {save_path}\")\n",
        "    except Exception as e:\n",
        "        print(\"Failed to open or save image:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijfiUQCYiV6A",
        "outputId": "f93bdb98-cf79-4049-fd75-4d69d8de0c7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully posted image to Instagram\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "product_name = \"WHITE HANGING HEART T-LIGHT HOLDER\"\n",
        "product_description = \"WHITE HANGING HEART T-LIGHT HOLDER,A fantastic product with amazing features!\"\n",
        "social_data = generate_social_media_post_and_meta_tags(product_name, product_description)\n",
        "\n",
        "# You would replace these with your actual credentials\n",
        "instagram_username = \"ValueDealsGlobal\"\n",
        "instagram_password = \"Delulu@321\"\n",
        "image_file_path = \"output.png\"  # Provide an image path\n",
        "\n",
        "post_to_instagram(\n",
        "    instagram_username,\n",
        "    instagram_password,\n",
        "    social_data[\"post_text\"],\n",
        "    image_file_path\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkYNzZd0if0g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1HdnjiLlYof"
      },
      "source": [
        "# **Event Based Trigger**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TeVwCXplc3a",
        "outputId": "fde273d2-36f1-41e8-f784-345b292dfa1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔔 Triggering actions for the next event: Easter Sunday on 2025-04-20\n",
            "✅ Email sent successfully to Lisa87@gmail.com\n",
            "✅ Email sent to customer 17511.0 for event: Easter Sunday\n",
            "✅ Email sent successfully to Megan75@gmail.com\n",
            "✅ Email sent to customer 15311.0 for event: Easter Sunday\n",
            "✅ Email sent successfully to Mark4@gmail.com\n",
            "✅ Email sent to customer 14646.0 for event: Easter Sunday\n",
            "⚡ Actions completed for the event: Easter Sunday\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import datetime\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Initialize the LLM using LangChain Groq\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# Initialize LangChain Groq LLM (update your API key and model as needed)\n",
        "llm = ChatGroq(\n",
        "    temperature=0.7,\n",
        "    groq_api_key='',\n",
        "    model_name=\"llama-3.3-70b-versatile\"\n",
        ")\n",
        "\n",
        "# Define the email prompt template for event-based emails\n",
        "prompt_email = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    ### CUSTOMER PURCHASE DATA:\n",
        "    Customer ID: {customer_id}\n",
        "    Products Bought:\n",
        "    {products_bought}\n",
        "\n",
        "    Recommended Products for the event \"{event_name}\":\n",
        "    {recommended_products}\n",
        "\n",
        "    ### INSTRUCTION:\n",
        "    Write a personalized, friendly, and professional email to the customer.\n",
        "    - Begin with a warm greeting thanking them for their recent purchase.\n",
        "    - List the products they bought.\n",
        "    - Suggest the recommended products that match the theme of {event_name}.\n",
        "    - Close with an invitation to check out these offers.\n",
        "    - DO NOT include any extraneous marketing jargon or preamble; return only the email content.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "def load_json_file(file_path):\n",
        "    \"\"\"Loads a JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {file_path}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Could not decode JSON from {file_path}\")\n",
        "        return None\n",
        "\n",
        "def generate_email(customer_id, products_bought, event_name, recommended_products):\n",
        "    \"\"\"\n",
        "    Generate a personalized, event-specific email using LangChain Groq.\n",
        "\n",
        "    Parameters:\n",
        "      - customer_id: The customer's ID.\n",
        "      - products_bought: List of products the customer purchased.\n",
        "      - event_name: Name of the upcoming event.\n",
        "      - recommended_products: List of relevant products based on event categories.\n",
        "\n",
        "    Returns:\n",
        "      - The generated email content as a string.\n",
        "    \"\"\"\n",
        "    # Prepare data for the prompt template\n",
        "    prompt_data = {\n",
        "        \"customer_id\": customer_id,\n",
        "        \"products_bought\": \"\\n- \".join(products_bought) if products_bought else \"No recent purchases\",\n",
        "        \"recommended_products\": \"\\n- \".join(recommended_products) if recommended_products else \"Our exclusive recommendations\",\n",
        "        \"event_name\": event_name\n",
        "    }\n",
        "\n",
        "    # Chain the prompt with the LLM\n",
        "    chain_email = prompt_email | llm\n",
        "    response = chain_email.invoke(prompt_data)\n",
        "    return response.content.strip()\n",
        "\n",
        "def send_email(to, subject, body, sender_email, sender_password):\n",
        "    \"\"\"\n",
        "    Send an email using SMTP SSL.\n",
        "\n",
        "    Parameters:\n",
        "      - to: Recipient's email address.\n",
        "      - subject: Subject of the email.\n",
        "      - body: Email content.\n",
        "      - sender_email: Sender's email address.\n",
        "      - sender_password: Sender's email password.\n",
        "    \"\"\"\n",
        "    msg = MIMEText(body, 'plain')\n",
        "    msg['Subject'] = subject\n",
        "    msg['From'] = sender_email\n",
        "    msg['To'] = to\n",
        "\n",
        "    try:\n",
        "        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:\n",
        "            server.login(sender_email, sender_password)\n",
        "            server.send_message(msg)\n",
        "        print(f\"✅ Email sent successfully to {to}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to send email to {to}: {e}\")\n",
        "\n",
        "def get_customer_purchases(customer_id, df):\n",
        "    \"\"\"\n",
        "    Return a list of up to 5 unique products purchased by the customer,\n",
        "    based on the Online_retail_email Excel file.\n",
        "\n",
        "    Parameters:\n",
        "      - customer_id: The customer's ID.\n",
        "      - df: Pandas DataFrame containing customer purchase data.\n",
        "\n",
        "    Returns:\n",
        "      - A list of up to 5 unique product descriptions purchased by the customer.\n",
        "    \"\"\"\n",
        "    # Filter rows where 'CustomerID' equals the given customer_id\n",
        "    customer_data = df[df[\"CustomerID\"] == customer_id]\n",
        "    # Extract the product descriptions from the \"Description\" column, remove missing values,\n",
        "    # and return unique items as a list.\n",
        "    products_bought = customer_data[\"Description\"].dropna().unique().tolist()\n",
        "    # Return only the first 5 items\n",
        "    return products_bought[:5]\n",
        "\n",
        "def get_customer_email(customer_id, df):\n",
        "    \"\"\"\n",
        "    Return the email address for a given customer ID based on the Online_retail_email Excel file.\n",
        "\n",
        "    Parameters:\n",
        "      - customer_id: The customer's ID.\n",
        "      - df: Pandas DataFrame containing customer data.\n",
        "\n",
        "    Returns:\n",
        "      - The customer's email address if found; otherwise, a default email.\n",
        "    \"\"\"\n",
        "    # Filter rows where 'CustomerID' equals the given customer_id\n",
        "    customer_data = df[df[\"CustomerID\"] == customer_id]\n",
        "    if not customer_data.empty and \"Email\" in customer_data.columns:\n",
        "        # Retrieve the email from the first matching record (assuming email is consistent per customer)\n",
        "        email = customer_data.iloc[0][\"Email\"]\n",
        "        return email\n",
        "    else:\n",
        "        return \"default@example.com\"\n",
        "\n",
        "def get_upcoming_events(events_data, days_ahead=20):\n",
        "    \"\"\"\n",
        "    Filter upcoming events within a specified timeframe.\n",
        "\n",
        "    Parameters:\n",
        "      - events_data: List of events from the event calendar JSON.\n",
        "      - days_ahead: Number of days ahead to check.\n",
        "\n",
        "    Returns:\n",
        "      - List of upcoming events.\n",
        "    \"\"\"\n",
        "    today = datetime.date.today()\n",
        "    upcoming_events = [\n",
        "        event for event in events_data\n",
        "        if today <= datetime.date.fromisoformat(event['date']) <= (today + datetime.timedelta(days=days_ahead))\n",
        "    ]\n",
        "    return upcoming_events\n",
        "\n",
        "def trigger_event_actions(filtered_customers_file, event_calendar_file, product_categories_file, event_to_product_mapping_file, sender_email, sender_password, df):\n",
        "    \"\"\"\n",
        "    Trigger personalized emails for the next upcoming event.\n",
        "    Combines filtered customer data, event calendar details, event-based products.\n",
        "\n",
        "    Parameters:\n",
        "      - filtered_customers_file: JSON file with filtered customers.\n",
        "      - event_calendar_file: JSON file with event details.\n",
        "      - product_categories_file: JSON file mapping event categories to products.\n",
        "      - event_to_product_mapping_file: JSON file containing LLM-generated event-to-product mappings.\n",
        "      - sender_email: SMTP sender email.\n",
        "      - sender_password: SMTP sender password.\n",
        "      - df: Pandas DataFrame containing customer data.\n",
        "    \"\"\"\n",
        "    # Load event calendar\n",
        "    event_calendar = load_json_file(event_calendar_file)\n",
        "    if not event_calendar:\n",
        "        return\n",
        "\n",
        "    # Load filtered customers data\n",
        "    filtered_customers_data = load_json_file(filtered_customers_file)\n",
        "    if not filtered_customers_data:\n",
        "        return\n",
        "\n",
        "    # Load product categories mapping\n",
        "    product_categories = load_json_file(product_categories_file)\n",
        "    if not product_categories:\n",
        "        return\n",
        "\n",
        "    # Load event to product mapping\n",
        "    event_to_product_mapping = load_json_file(event_to_product_mapping_file)\n",
        "    if not event_to_product_mapping:\n",
        "        return\n",
        "\n",
        "    # Find the next upcoming event (using event_calendar.json)\n",
        "    upcoming_events = get_upcoming_events(event_calendar, days_ahead=90)\n",
        "    if not upcoming_events:\n",
        "        print(\"⚠ No upcoming events found!\")\n",
        "        return\n",
        "\n",
        "    # Select the first upcoming event\n",
        "    next_event = upcoming_events[0]\n",
        "    event_name = next_event['name']\n",
        "    event_date = next_event['date']\n",
        "    event_categories = next_event.get('categories', [])  # Example: [\"religion\", \"faith\"]\n",
        "\n",
        "    print(f\"🔔 Triggering actions for the next event: {event_name} on {event_date}\")\n",
        "\n",
        "    # Retrieve the filtered customers for the event from filtered_customers.json\n",
        "    filtered_customers = None\n",
        "    for event in filtered_customers_data:\n",
        "        if event['event_name'] == event_name:\n",
        "            filtered_customers = event['filtered_customers']\n",
        "            break\n",
        "\n",
        "    if not filtered_customers:\n",
        "        print(f\"⚠ No filtered customers found for the event: {event_name}\")\n",
        "        return\n",
        "\n",
        "    # Get the mapped product category for the event\n",
        "    mapped_categories = event_to_product_mapping.get(event_name, {})\n",
        "    recommendations = []\n",
        "\n",
        "    for event_category in event_categories:\n",
        "        mapped_category = mapped_categories.get(event_category)\n",
        "        if mapped_category and mapped_category in product_categories:\n",
        "            category_products = product_categories[mapped_category]\n",
        "            if category_products:\n",
        "                # Select up to 5 random products from the category\n",
        "                recommendations.extend(random.sample(category_products, min(5, len(category_products))))\n",
        "\n",
        "    limited_recommendations = recommendations[:5]  # Limit to 5 products for the email\n",
        "\n",
        "    # Select 3 random customers from the filtered list\n",
        "    num_customers_to_send = min(3, len(filtered_customers))\n",
        "    selected_customers = random.sample(filtered_customers, num_customers_to_send)\n",
        "\n",
        "    # For each of the selected customers, generate and send a personalized email\n",
        "    for customer_id in selected_customers:\n",
        "        products_bought = get_customer_purchases(customer_id, df)\n",
        "        # Generate the email content using LangChain Groq prompt template\n",
        "        email_content = generate_email(customer_id, products_bought, event_name, limited_recommendations)\n",
        "        customer_email = get_customer_email(customer_id, df)\n",
        "        subject = f\"Exclusive Offers for {event_name}\"\n",
        "        send_email(customer_email, subject, email_content, sender_email, sender_password)\n",
        "        print(f\"✅ Email sent to customer {customer_id} for event: {event_name}\")\n",
        "\n",
        "    print(f\"⚡ Actions completed for the event: {event_name}\\n\")\n",
        "\n",
        "# Example Usage\n",
        "\n",
        "filtered_customers_file = \"filtered_customers (1).json\"  # Contains list of events with filtered customer IDs\n",
        "event_calendar_file = \"/content/updated_event_calendar.json\"  # Contains event details (name, date, categories, etc.)\n",
        "product_categories_file = \"/content/product_categories_keywords.json\"  # Maps event categories to products\n",
        "event_to_product_mapping_file = \"event_to_product_mapping.json\" # Contains LLM generated event to product mapping\n",
        "sender_email = \"mrunaldgund04@gmail.com\"  # Replace with your email\n",
        "sender_password = \"buvs vwzc waug wwvv\"\n",
        "\n",
        "\n",
        "trigger_event_actions(filtered_customers_file, event_calendar_file, product_categories_file, event_to_product_mapping_file, sender_email, sender_password, df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al-uJ4-plreM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
